亿级流量学习

=================================


scp： linux跨服务器复制文件命令

cp -r： 复制文件夹(包括子文件)

cat： 显示某个文件内容


===================================
使用nginx做负载均衡(nginx分发层和nginx应用层)

nginx分发层将根据请求参数进行hash取模，将请求分发到某个固定的应用层nginx中(opentrety)


应用层nginx首次收到请求，会执行lua脚本，脚本会请求后台服务(redis服务)获取目标数据，之后会将脚本写到lua渲染html模板中，并缓存html结果写到nginx本地缓存中


分布式环境下，不同节点重构缓存数据时，可能导致缓存数据不是最新数据的问题存在(如：两个节点都发起了全量redis缓存重组，结果后请求的数据先写入redis了，先请求的数据反而后写入了redis，导致redis的数据被旧版本覆盖了)
解决方法：使用分布式锁给请求加锁(使用zk)




========================
以热点商品访问top计算为例（热点数据预热，防止冷启动导致大量数据直接访问数据库）：
lua脚本将每个商品请求信息写入kafaka中，再由strom进行分析(分类汇总求和)，计算出top热点数据(记录所有访问商品的访问次数，通过lru算法进行排序)，并将top数据写入到zksession中，另开线程，每个服务在启动前就可以从zksession中获取到热点数据(过程需要加解锁，防止数据覆盖)，将之写入缓存进行预热，


========================

实时性高的数据，使用异步内存队列进行数据库和缓存双写

实时性低的数据，使用异步消息队列进行多级缓存写入
(修改一条数据后，将改动写入数据库，之后创建一条信息写入MQ中，有另外的服务会监听MQ队列，将对应数据解析出来，再写入到缓存中(reids、encache等))


=========================

短时间某个商品大量的访问请求会导致某台nginx或redis 挂掉问题：

在storm中实时计算的lru列表中，我们可以拿到已经排好序(按访问量排序)的商品请求列表， 我们通过对这个列表的80%~95%的商品求平均值，再遍历每个元素，筛选出大于10*平均值的商品信息，
这些商品就是热点数据了，专门存到一个hotList中。


遍历hotList，让每个商品的id作为参数去请求分发层nginx和应用层nginx，把这些热点数据缓存到本地。



分发层nginx可以只接受缓存商品id，用于判断该商品是否是热点数据，再来决定采用何种访问数据方式(热点数据需要采取轮询让所有nginx负载热点流量，非热点数据可以访问定点hash nginx服务器)

应用层nginx除了接受缓存商品id外，还需要缓存商品的全部信息，这样热点就不用访问数据库了

=========================


redis cluster多主多从架构适合普通的高并发架构

redis一主多从架构则适合单点数据数据的高并发场景，例如某商品的秒杀抢购