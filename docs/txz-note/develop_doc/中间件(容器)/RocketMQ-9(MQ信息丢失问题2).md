### 消息存储到MQ中就不会丢失吗？

答案肯定是否定的，数据不丢失从来就是一个伪命题，只能通过手段尽可能的保证数据不丢失，减少异常丢失的可能性。

在消息发送MQ后，有哪些地方可能会导致数据丢失呢？

之前我们知道了一条消息进入MQ的某个主Broker节点中，会将这条数据进行进行持久化，同时会将这条数据同步给从Broker节点中。

![image-20230403111346231](https://alex-img-1253982387.cos.ap-nanjing.myqcloud.com/Typora-wm/202304031113452.png)

那么数据丢失就有这么两种可能：

- MQ收到消息还未持久化，比如写入OS Cache到还未落盘，当前Broker节点宕机了
- MQ收到消息持久化到磁盘了，但是所在服务器磁盘损坏了。

**问题一处理**：

对于情况一，我们可以将RocketMQ的持久化策略从异步刷盘改为同步刷盘即可，这样MQ只有在消息已经落盘了，才会给生产者返回ACK。

RocketMQ中持久化策略配置参数为flushDiskType，默认策略是ASYNC_FLUSH，即异步刷盘，改为同步刷盘策略：SYNC_FLUSH。

但是这样会导致MQ性能降低，需要根据实际业务场景来进行选择。

**问题二处理**：

对于问题二，这就需要依靠Broker集群的主从节点，数据冗余机制来保证一条消息会同时存在于多个Broker节点中，单Broker磁盘的损坏并不会导致数据的丢失。

### 消费者消费数据会导致数据丢失？

通过之前的学习，我们清楚了，生产者可以通过发送Half事务消息和维护一张消息发送状态表来保证数据在发送到MQ的过程中不会丢失；

MQ通过修改刷盘策略为同步刷盘和配置高可用主从Broker节点集群来保证数据不会在MQ中丢失。

那么消费者如何保证数据一定被成功消费，不会丢失的呢？

答案的关键在于，一定要消费者成功处理消费完数据之后再给MQ回应消费完成的ack，而不是在接收到消息后还没有处理完，就直接将消费信息的offset更新返回给MQ。这样可能会导致消费者给MQ返回ack了，但是在后续的处理过程中，消费者机器宕机了没有完成当前信息的消费业务，但是MQ对于当前信息的消费状态是已完成消费，这就出现了数据不一致的情况。

如果用的MQ是kafka，在严格保证数据不丢失的场景下，那么一定要关闭kafka的自动提交，用手动提交的方式在消息消费完成之后再提交数据。

### MQ零数据丢失问题总结

想要数据零丢失，就势必要付出性能的成本，此前的学习中，从生产者发送消息到MQ，MQ消息的存储过程，MQ发送信息到消费者完成消费；这三个过程里，为了实现数据不丢失，保证数据的一致性，做了诸多的设计或限制。

- **保证MQ一定接收到生产者发送的消息**：生产者使用Half事务消息进行发送，胡总使用同步信息发送+重试机制+人工补偿的方式来保证数据一定发送成功。
  **代价**：需要多阶段与MQ进行请求发送确认，或是多次重试机制等，都需要多次请求的耗时。
- **保证MQ收到消息存储过程不丢失**：MQ设置使用同步刷盘策略，保证数据一定会落盘；又使用高可用多主从节点集群，保证数据会同步到其他从节点中，不会因为一个主Broker节点磁盘损失导致数据丢失。
  **代价**：每条信息只有在磁盘持久化和同步到其他从broker节点后，才会给生产者返回消息发送成功的结果
- **保证消费者成功的消费到MQ中的消息**：采用手动消息消费提交方式，只有消费者成功消费当前消息后，才会提交消息的offset给broker。
  **代价**：每条消息只有在被成功消费后才会给MQ返回消息消费成功的ACK

这些代价会让整个链路的性能急剧下降，所以除非是涉及和金钱相关的重要敏感信息外，尽量少的使用这种全链路零数据丢失方案。

通常可以适当降低这个“零丢失”的方案档次，采用原本高效的信息消费方案+人工补偿数据的策略来应对大多数使用场景。

### 如何保证MQ消息不会被重复消费

使用MQ后，由于增加了系统的复杂度，可能会出现同一条消费重复消费的情况，可能是生产者因为超时重试等机制发送了重复的数据，也可能是消费者宕机导致一条数据被消费了多次。

对于这个问题，我们可以在生产者一侧进行处理，需要保证生产者不会发生重复的数据给MQ，例如每次发生消息前，去MQ里查询一下当前消费是否已经被发送了。或者消息发送成功后使用redis记录一下当前消息，那么无论任何情况，当生产者需要重复发送一条数据时，就有方法知道当前消息是否已经发生过了。

但是，我们需要考虑的一个问题是，生产端处理重复消息，并不能绝对保证这条消息一定不会被重复消费，因为消费端的服务也可能会出各种各样的问题，重复消费的问题也可能存在，所以应该允许生产者发送重复的数据。处理重复数据问题应该在消费端进行。

一般的处理方式是：**redis分布式锁+mysql表唯一键来保证幂等操作**

对于每条消息，使用Redis中的SETNX命令设置一个唯一的键（例如使用消息ID）并附带一个过期时间。如果这个键不存在，说明是第一次处理这条消息，执行业务逻辑，并设置过期时间；如果键已经存在，说明已经处理过这条消息，则直接忽略；当消息处理完成后，写入redis并删除当前redis锁。

如果后续再发送当前消息，则数据库唯一键会保证当前数据的唯一性。
