redis-6(秒杀架构设计)

### 秒杀架构设计

#### 传统系统架构

1.传统的系统架构一般时这样的，用户通过html页面访问到系统，在页面中点击按钮链接产生后台请求，这些请求到达后台服务后会根据相应的逻辑去数据库查询数据，最后将数据库查询结果返回到html页面展示给用户。示意图如下：

![image-20210406103131877](https://alex-img-1253982387.cos.ap-nanjing.myqcloud.com/Typora/20210406103151.png)

2.传统架构的问题：对于上面描述的这种传统架构，每产生一次后台数据请求，就需要访问一次数据库，后台服务和数据库服务是连在一起的高耦合状态，当请求量增加到一个量级时，就必然会导致其中一个服务性能到达极限，从而导致崩溃宕机。这样一来此架构就不能再满足当前业务的需求了，需要对这种单一的架构进行优化改造。

3.如何优化传统架构呢，主要从三个方面来做：

**一、页面请求与后台请求分离，并且静态化**

将传统的JSP、Freemaker、ThymeLeaf从后台中分离出来，将页面静态化成html(或者用VUE等前端语言重构)，部署在nginx等服务器上，做单独的页面请求响应。这样后端服务就不用管html、css、js、图片等资源的请求了。

**二、后端服务负载均衡部署**

为了保证后台服务的高可用性，一般会将同一套后台代码部署在多个服务器上，产生多个后台服务。然后由至少一台nginx服务器做反向代理，将用户的请求分给部署的多个后台服务中。

**三、数据库服务做读写分离**

面对大数据量的请求，如果全部打到一台数据库上，那么数据库必然会承受不了大的访问量而崩溃。最简单的处理方式就是，搭建主从分离数据库架构，实现数据库的读写请求分离。所有用户写的数据库请求走主数据库，再由主库将最新数据同步给从库，而所有的读数据库请求走从数据库，这样只要主库能承受当前的写数据请求量，那么无论多大的读请求量都可以通过从库的横向扩展来满足要求。

总体的结果示意图如下：

![image-20210406112649669](https://alex-img-1253982387.cos.ap-nanjing.myqcloud.com/Typora/20210406112649.png)

可以的话，还可以让nginx缓存一些静态资源，以及在后台服务中增加redis等缓存服务，减少到达数据库的有效请求

#### 秒杀系统架构

4.上面的系统架构优化后，一定程度上可以承受较高的用户请求量了。但是这种架构是很难承受瞬时的高并发请求场景，例如商品活动秒杀等短时间会产生大量的请求，所以争对这种非寻常的瞬时高并发访问场景，需要进行独特的架构设计。

**静态化页面的产生方式的调整**

运维人员手工调整html静态化->用户修改数据，通过MQ发送修改后的信息生成新html

**html模块化**

将一个html中不同维度的数据分成一个个的html片段，nginx通过ssi技术组合片段成一个完整的页面响应请求，当一个一个片段数据源改变时，仅改变html的片段即可(问题：片段会过多，如果页面结构发生变化需要全量调整)。

再次优化：nginx仅缓存页面模板，由lua脚本(到redis)请求拉取页面需要的数据，然后nginx动态渲染到模板中，读取到的数据会进行本地缓存，下一次访问直接读取本地数据。

整体架构图如下：

![秒杀系统架构-第 2 页](https://alex-img-1253982387.cos.ap-nanjing.myqcloud.com/Typora/20210406154726.jpg)
整个逻辑如下：
用户请求---->nginx分发层根据lua脚本(根据ip、商品id等hash/轮询)确定当前请求会被转发给nginx应用层中的哪个节点--->nginx 应用层如果有当前请求的缓存则直接返回；如果没有，则使用lua脚本创建http请求到java服务中获取请求数据，然后通过lua脚本将数据渲染到html模板中，再由nginx缓存起来(10min)，供之后的请求直接使用---->nginx 应用层http请求缓存服务中后，先读取redis，看看是否有redis缓存数据，再读取encache本地缓存，如果都没有则请求到商品服务直接去数据库读取

##### 秒杀场景的特别处理

1.秒杀页面直接静态化。秒杀的商品页面全部作静态化处理(点击提交按钮置灰，增加验证码)

1.1提前预约，只有预约成功后，才能购买

2.CDN页面缓存。通过各地市的CDN服务器缓存，减少真正到达中后台服务

3.限流(秒杀数量*120%左右)。限制真正到达中后台的有效请求在秒杀商品总数的1.1倍或1.2倍

4.redis集群，redis服务最好以集群的形式部署，保证高可用。

5.使用redis nx创建自旋锁，让每次只有一个线程能获取锁，其他线程自旋等待，等待线程超时直接返回。

6.获取锁后，使用数据库或redis(或者lua调用redis的脚本)进行库存扣减
s数据库版：update table_1 set stock = stokc -1 where id = 11 and stock > 0;
redis版：if(redis.incr("stock", -1) >0){库存扣减}

7.使用nginx或redis对同一IP进行请求次数限流

8.使用MQ异步化，秒杀成功的用户生成延时消息发送到MQ中，状态是待支付，如果15分钟内没有支付，那么消费者会消费此条消息，释放库存；如果期间用户已经支付，那么将状态改为已支付，这样在消费者消费延迟消息时，判断订单状态，如果状态不是待支付，则直接返回。

#### 并发竞争问题

如果在某个高并发的场景下，多个客户端对同一个key进行写请求，可能导致旧数据将新数据覆盖掉：

正常顺序：v1--->v2--->v3

问题顺序：v1--->v3--->v2

处理方式：

方案一：分布式锁+时间戳

在给redis进行写请求前，需要获取分布式锁(zk、redis的nx等都可以)，将请求串行化；

同时还需要给value加一个时间戳进行版本判断，如果某个请求拿到锁后，发现自己的时间戳小于redis数据当前的时间戳则放弃写入

方案二：消息队列串行化