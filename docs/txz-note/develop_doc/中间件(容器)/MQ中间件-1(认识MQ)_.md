MQ中间件-1(认识MQ)

### 认识MQ

#### 一、引入MQ前的系统体系

通过系统双方规定统一接口请求来进行数据通信，这样常规的接口在系统体量扩大后会有非常多的问题：

- 两个系统强耦合、一方接口变更，另一方也有变更工作量
- 性能差，如果接口执行时间过长，会导致本系统应用给用户的体验不佳
- 不稳定，如果接口调用失败出现异常，无法很快的定位处理问题，而且请求可能会丢失导致脏数据

#### 二、系统的请求压力在哪里？

- 系统请求过多，影响网络带宽负载
- 请求创建对象过多，影响应用内存负载
- 请求计算需求强，影响CPU负载
- 请求需要读写磁盘数据，影响服务器IO性能
- 磁盘大小、性能等等因素

#### 三、引入MQ消息队列的优势

MQ是可以独立部署存在的一个系统中间件，他的作用和数据库类似就是存储请求数据，只不过稍稍不同的是MQ中的数据是事件响应数据，简单理解就是每条数据被消费后会返回一个消费状态，判断这条数据是否消费成功。这些数据由上游生产者系统发生到MQ中，由下游消费者系统执行消费，承担一个数据快递中转的功能角色。

那么引入MQ有什么好处呢？主要有以下几点：

- 系统解耦，请求异步化，生产者系统将请求发送给MQ后就可以返回结果，下游系统何时去消费这条请求数据和生产者系统没有直接关系了
- 请求流量削峰，当系统面临较大的请求数据量时，可以将这些数据存到MQ中，然后再慢慢消化后续的业务流程，不会让这些高并发请求直接打到数据库或其他系统中
- 异常请求重试，当MQ的消息消费失败时，可以让MQ去重试这些失败数据，当失败数据重试到一个上限次数时，可以将之存储到数据库中，由运维人员手工处理。

#### 四、MQ的技术选型

MQ的几种技术选型如下：ActiveMQ、RabbitMQ、Kafka、RocketMQ、ZeroMQ、MetaMQ等等

- ActiveMQ早些年使用较多，现在多已不再使用，吞吐量比Kafka、RocketMQ低一个级别，社区活跃度不高，依靠主从架构实现可用性
- RabbitMQ是现如今主流MQ之一，可以实现数据不丢失，服务高可用，死信队列、消息重试等功能。但是缺点也有不少，吞吐量比Kafka、RocketMQ低一个级别，而且是使用erlang语言开发，扩展困难，集群部署也比较麻烦等等
- Kafka是近些年新出一个MQ，性能极佳，可以达到几十万QPS，但是这个MQ在数据持久化方面不是数据直接落盘、而是先写入缓冲区中，所以会有数据丢失的可能；而且功能较为单一，适用场景不多，现多用于各种日志信息的采集工作
- RocketMQ也是近些年阿里的一个MQ，性能和Kafka类似也很好，而且支持分布式高可用部署，适用JAVA语言开发，扩展也较为简单，是很多公司比较中意的一个MQ

#### 五、引入MQ技术的场景

并不是所有情况下都要引入MQ，或者说为了使用MQ而引入MQ。一定要根据系统的具体应用场景而定：

1.判断系统面临的问题是什么，是流量太大，还是瞬时流量太大，还是什么问题？

2.通过增加负载均衡能不能缓解系统的请求压力？

3.通过增加多级缓存、或给数据库设置成主从架构(读多写少)，或者分库分表(写多读少)等操作能否缓解数据库压力？

4.系统数据的实时性要求很高？

5.如果上述方法都解决不了问题，那么才能考虑引入MQ。MQ的主要作用是对系统调用进行异步解耦，加快系统反应速度；以及流量削峰，能大量存储上游系统请求，缓解数据库压力；同时如果系统下游系统过多而且经常增加变化，也可以使用MQ进行平滑扩展。

#### 六、MQ存在的问题

引入MQ会导致系统的复杂度提高，带来方便的同时也会导致新的问题存在：

##### MQ的高可用问题？

队意MQ而言，一般是不会进行单机部署的，一旦单机宕机了，那么会导致系统之间的通信中断，所以MQ一般会采用高可用部署。

高可用部署分为常规高可用和分布式高可用两种：

-常规高可用以RabbitMQ为例，RabbitMQ可以进行单机部署、普通集群部署、镜像集群部署三种。

其中普通集群部署和主从架构类似，生产者会往RabbitMQ集群中的某个节点(主节点)中的Queue中写数据，其他实例会从这个主节点中同步数据，所以如果主节点挂了那么整个集群也就挂了

而镜像集群部署则是生产者会往RabbitMQ集群中的每个节点都发送一条数据，每个节点的数据是相同的 ，类似负载均衡部署。开启方式也比较简单，在可视化界面中配置镜像部署策略，在之后的几点搭建中给节点选择镜像策略就行了。

-分布式部署以Kafka为例，生产者往kafka集群中发送消息时会将消息写入到某个leader节点中，之后这个leader的从节点会拉取这条数据到foller节点中，当所有的从节点都同步完数据了，会发送ack给leader节点，当leader节点收到所有从节点的ack时就会给生产者发送一个写消息成功的消息。

整个集群中会有多个leader节点存在，每个leader节点可以挂多个foller节点，而每个leader指挥存储一部分消息数据，整个leader节点群堆外表现为一个整体。消费者一般也指挥从leader节点中拉取数据消费，一旦某个leader节点宕机了，那么就会选出一个从节点来作为新的leader节点，保证可用性。

------

##### 消息重复消费问题？

也就是如何保证消费者的幂等问题，这个问题需要做的就是消费者记录每一条消费过的记录(需要给每条数据一个唯一值，比如数据库递增值，或者时间戳)，不管是基于数据库也好，还是redis或是内存set集合也好；这样在消费任何一条数据时，先根据消息唯一值去查询释放存在消费记录。存在就是重复数据，不存在就是新来的数据。

------

##### 消息数据丢失问题？

引入MQ后消息可能会因为各种问题导致消息丢失，主要有3中丢失情况：

1.生产者发送消息到MQ因为网络波动等问题，导致MQ么有收到数据

2.MQ在运行时宕机，导致的数据丢失

3.消费者消费消息时宕机导致的数据丢失

下面以RabbitMQ和kafka两种MQ为例来说明这个问题：

**生产者如何确保消息一定发送到RabbitMQ？**解决方案有两种：

一种是使用事务，在发送消息后将消息作为事务提交到MQ，如果MQ成功收到消息会返回标记给生产者，生产者才会继续执行代码，所以这是一种同步阻塞式的做法，所以效率可能不会太高，一般不建议使用。

另使用时异步回调确认方式，即生产者还是异步发送消息到MQ，MQ在收到消息后会回调生产者的接口告诉生产者收到了数据，这种方式才是常用的方式，但是回调过程也可能会出问题，所以最好的方式是在生产者这边需要维护一个消息发送记录表到数据库，MQ回调时，将记录状态改为已发送，这样就可以做一个定时任务来处理没有发送成功的数据。

**RabbitMQ如何确保数据不丢失呢？**

这就需要MQ开启持久化功能了，需要将Queue的元数据和队列数据都持久化到磁盘中，Queue的元数据持久化在创建时设置持久化参数即可，队列数据持久化需要生产者发送消息时将deliveryMode参数设置为2。

由于MQ的持久化也是异步定时的，所以也会存在MQ数据还未持久化就宕机导致数据丢失的去重。

**消费者如何确保消息成功消费呢？**

去掉消费端默认的autoAck设置，有开发者在接受到消息处理完后手动发送ack信息给MQ，即使过程中消费者宕机了，MQ还是会进行重试消费这条信息。

------

而对于kafka而言在者三个方面又是如何做的呢？

生产者方面，通过设置参数acks =all保证kafka的leader和所以foller节点都同步完发送的消息后，才能认为这条消息发送成功；同时设置参数retries=MAX代表消息写入MQ失败会无限重试(可以优化？)

消费者方面，kafka是通过消息的offset标记来保证信息的唯一性的，和RabbitMQ类似，将消费者的自动提交offset关闭，改成消费者手动提交offset来告诉kafka消息成功消费。

kafka持久化方面，由于消费者只会从leader节点中消费信息，如果一条消息刚发到leader节点还没有同步到从节点中，leader节点就宕机了，leader节点的数据就永久丢失了，那么就需要设置topic有多个partition分片备份(物理层面上存储消息的容器，一个topic有多个partition分片，不是直接写入broker中的)，这样即使leader节点宕机那么leader的partition分片备份也可以同步给从节点，当一个从节点被选举为新的leader，那么也不会丢失数据。

replication.factor参数设置为大于1，即partition分片备份大于1

min.insync.replicas参数设置为大于1，即每个leader至少有1个可用的foller节点

------

##### 消息顺序一致性如何保证？

要保证一致性需要让有先后关系的多条数据被同一个消费者按顺序消费，在RabbitMQ中，需要将关联消息发送到同一个Queue中，因为一个Queue是只会将消息分发给同一个消费者的，而对于kafka而言需要将消息放到同一个partition分片中，每个partition只会发送消息给同一个消费者。

此外，对于消费者而言如果采用多线程来消费消息的话，也需要考虑消息处理的一致性问题，最好给每一个处理线程设置一个内存队列，线程从内存队列中消费任务，而消费者从MQ获取的销毁会根据类型字段进行hash来对消息队列取余，保证相关联的消息会被放到同一个内存队列中。

* * *

##### 消息出现积压了怎么办？

1、大量积压：如果是kafka，那么就将topic的partition增加10倍，将原来的消费者程序修改一下，写回MQ中，这样就可以快速的消费掉积压的数据。但是如果消费过程中存在一些问题，比如DB压力，或者第三方调用等等还需要考虑。 2、RabbitMQ设置了TTL数据丢失：夜深人静时，查出来再倒入。但是如果是消费信息，第三方有过期时间，就完蛋了，所还是别设置这个。 3、挤压到磁盘满了：直接丢掉或者往其他地方写，快速消费掉，再想办法补偿。











